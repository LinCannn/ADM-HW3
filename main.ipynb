{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting we import all the libraries that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myFunctions import *\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <strong> Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong> 1.1 Get the list of Michelin restaraunts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before scraping all the restaurant URLs, let's first determine the maximum page number. It's simple to find the correct CSS selector for the page list: just inspect the list of pages in your browser and identify the corresponding class or element name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img title = \"list of pages\" src=\"images/pages_number.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are in total: 102 pages\n"
     ]
    }
   ],
   "source": [
    "response = requests.get('https://guide.michelin.com/en/it/restaurants')\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "page_links = soup.select('ul.pagination li a') #name of the pages list\n",
    "page_numbers = [int(a.get_text()) for a in page_links if a.get_text().isdigit()]\n",
    "\n",
    "# Get the maximum page number\n",
    "total_pages = max(page_numbers) if page_numbers else 0\n",
    "print(f'There are in total: {total_pages} pages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can very easily get the URL of each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = ['https://guide.michelin.com/en/it/restaurants'] #Initial page\n",
    "\n",
    "for i in range(2, total_pages+1): #get all other pages from 2 to total_pages included\n",
    "    pages.append('https://guide.michelin.com/en/it/restaurants/page/'+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in order to get the URLs of all the restaraunts, we proceed the same by identifying the name of the corresponding class in the webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img title = \"Class of a restaraunt\" src=\"images/restaurant_link.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that the restaurant URLs follow a consistent pattern, which can be expressed using the regular expression:\n",
    "\n",
    "```bash\n",
    "BASE_URL/en/region/city/restaurant/name_of_restaurant\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_urls = [] #save all urls\n",
    "base = 'https://guide.michelin.com' #base url to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in pages: #loop all pages\n",
    "    response = requests.get(p) #get the page\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\") # we use BeautifulSoup to get the content\n",
    "    links = soup.select('a.link') #select all the class 'a link'\n",
    "    pattern = re.compile(r'^/en/[^/]+/[^/]+/restaurant/[^/]+$') #pattern of restaurants\n",
    "    restaurant_links = [base+link.get('href') for link in links if pattern.match(link.get('href', ''))] #get all the restaurants links\n",
    "    total_urls.append(restaurant_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we save all the urls inside a txt called 'restaurant_urls.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('restaurant_urls.txt', 'w') as f: \n",
    "    page_count = 1  # Initialize the page count\n",
    "    for urls in total_urls:\n",
    "        f.write(f'Page {page_count}:\\n')  # Add a label for the page number\n",
    "        for url in urls: # Write each URL from the current page\n",
    "            f.write(f'{url}\\n')  \n",
    "        \n",
    "        page_count += 1 # Increment the page count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2037\n"
     ]
    }
   ],
   "source": [
    "print(sum([len(u) for u in total_urls])) # how many restaurants we got"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong> 1.2. Crawl Michelin restaurant pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we download all the HTML from the urls and save them in a folder and divide each of them in separate folder_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all_as_html('restaurant_urls.txt') # See actual implementation inside 'myFunctions.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file count: 2034\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for root_dir, cur_dir, files in os.walk('restaurants_html'): #Let's check if we got all the files\n",
    "    count += len(files)\n",
    "print('file count:', count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The save_all_as_html function utilizes multi-threading to achieve optimal performance, generating approximately 20 threads concurrently. Within each loop for a page, each thread is tasked with downloading around a single URL, making it extremely efficient. Consequently, the function successfully downloaded 2,034 out of 2,037 files in under one minute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong> 1.3 Parse downloaded pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of the information we desire for each restaurant and their format is as follows:\n",
    "\n",
    "    Restaurant Name (to save as restaurantName): string;\n",
    "    Address (to save as address): string;\n",
    "    City (to save as city): string;\n",
    "    Postal Code (to save as postalCode): string;\n",
    "    Country (to save as country): string;\n",
    "    Price Range (to save as priceRange): string;\n",
    "    Cuisine Type (to save as cuisineType): string;\n",
    "    Description (to save as description): string;\n",
    "    Facilities and Services (to save as facilitiesServices): list of strings;\n",
    "    Accepted Credit Cards (to save as creditCards): list of strings;\n",
    "    Phone Number (to save as phoneNumber): string;\n",
    "    URL to the Restaurant Page (to save as website): string.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To parse those information we can just inspect one html to see how those information are stored as we did before.<br>\n",
    "Most of the information can be retrieved in the following json script at the end of each HTML file:\n",
    "```js\n",
    "<script type=\"application/ld+json\">{\"@context\":\"http://schema.org\",\"address\":{\"@type\":\"PostalAddress\",\"streetAddress\":\"Piazza Salvo d'Acquisto 16\",\"addressLocality\":\"Lamezia Terme\",\"postalCode\":\"88046\",\"addressCountry\":\"ITA\",\"addressRegion\":\"Calabria\"},\"name\":\"Abbruzzino Oltre\",\"image\":\"https://axwwgrkdco.cloudimg.io/v7/__gmpics3__/f19d37d6b9da437fa06b6f9406645056.jpg?width=1000\",\"@type\":\"Restaurant\",\"review\":{\"@type\":\"Review\",\"datePublished\":\"2024-09-11T07:32\",\"name\":\"Abbruzzino Oltre\",\"description\":\"This restaurant, the new home of young chef Luca Abbruzzino, occupies the first floor of a historic palazzo in the town centre which has recently been converted into a small hotel offering six ...\",\"author\":{\"@type\":\"Person\",\"name\":\"Michelin Inspector\"}},\"telephone\":\"+39 0968 188 8038\",\"knowsLanguage\":\"en-IT\",\"acceptsReservations\":\"No\",\"servesCuisine\":\"Contemporary\",\"url\":\"https://guide.michelin.com/en/calabria/lamezia-terme/restaurant/abbruzzino-oltre\",\"currenciesAccepted\":\"EUR\",\"paymentAccepted\":\"American Express credit card, Credit card / Debit card accepted, Mastercard credit card, Visa credit card\",\"award\":\"Selected: Good cooking\",\"brand\":\"MICHELIN Guide\",\"hasDriveThroughService\":\"False\",\"latitude\":38.9770969,\"longitude\":16.3202202,\"hasMap\":\"https://www.google.com/maps/search/?api=1&query=38.9770969%2C16.3202202\"}</script>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/restaurant_page.png' width=\"1200\" height=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restaurantName: Abbruzzino Oltre\n",
      "address: Piazza Salvo d'Acquisto 16\n",
      "city: Lamezia Terme\n",
      "postalCode: 88046\n",
      "country: ITA\n",
      "region: Calabria\n",
      "priceRange: €€€€\n",
      "cuisineType: Contemporary, Mediterranean Cuisine\n",
      "description: This restaurant, the new home of young chef Luca Abbruzzino, occupies the first floor of a historic palazzo in the town centre which has recently been converted into a small hotel offering six ...\n",
      "facilitiesServices: ['Air conditioning']\n",
      "creditCards: ['Amex', 'Mastercard', 'Visa']\n",
      "phoneNumber: +39 0968 188 8038\n",
      "website: http://www.abbruzzinoltre.it\n"
     ]
    }
   ],
   "source": [
    "parse_restaurant('/home/pavka/ADM/ADM-HW3/restaurants_html/1/abbruzzino-oltre.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
