{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting we import all the libraries that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyFunctions.crawler import Crawler\n",
    "from MyFunctions.parser import Parser\n",
    "from MyFunctions.preprocessor import Preprocessor\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from nltk import word_tokenize\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <strong> Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong> 1.1 Get the list of Michelin restaraunts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before scraping all the restaurant URLs, let's first determine the maximum page number. It's simple to find the correct CSS selector for the page list: just inspect the list of pages in your browser and identify the corresponding class or element name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <img title = \"list of pages\" src=\"./images/pages_number.png\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are in total: 100 pages\n"
     ]
    }
   ],
   "source": [
    "response = requests.get('https://guide.michelin.com/en/it/restaurants')\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "page_links = soup.select('ul.pagination li a') #name of the pages list\n",
    "page_numbers = [int(a.get_text()) for a in page_links if a.get_text().isdigit()]\n",
    "\n",
    "# Get the maximum page number\n",
    "total_pages = max(page_numbers) if page_numbers else 0\n",
    "print(f'There are in total: {total_pages} pages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can very easily get the URL of each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = ['https://guide.michelin.com/en/it/restaurants'] #Initial page\n",
    "\n",
    "for i in range(2, total_pages+1): #get all other pages from 2 to total_pages included\n",
    "    pages.append('https://guide.michelin.com/en/it/restaurants/page/'+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in order to get the URLs of all the restaurants, we proceed the same by identifying the name of the corresponding class in the webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<img title = \"Class of a restaraunt\" src=\"images/restaurant_link.png\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that the restaurant URLs follow a consistent pattern, which can be expressed using the regular expression:\n",
    "\n",
    "```bash\n",
    "BASE_URL/en/region/city/restaurant/name_of_restaurant\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_urls = [] #save all urls\n",
    "base = 'https://guide.michelin.com' #base url to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in pages: #loop all pages\n",
    "    response = requests.get(p) #get the page\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\") # we use BeautifulSoup to get the content\n",
    "    links = soup.select('a.link') #select all the class 'a link'\n",
    "    pattern = re.compile(r'^/en/[^/]+/[^/]+/restaurant/[^/]+$') #pattern of restaurants\n",
    "    restaurant_links = [base+link.get('href') for link in links if pattern.match(link.get('href', ''))] #get all the restaurants links\n",
    "    total_urls.append(restaurant_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we save all the urls inside a txt called 'restaurant_urls.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/restaurant_urls.txt', 'w') as f: \n",
    "    page_count = 1  # Initialize the page count\n",
    "    for urls in total_urls:\n",
    "        f.write(f'{page_count}\\n')  # Add a label for the page number\n",
    "        for url in urls: # Write each URL from the current page\n",
    "            f.write(f'{url}\\n')  \n",
    "        \n",
    "        page_count += 1 # Increment the page count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1983\n"
     ]
    }
   ],
   "source": [
    "print(sum([len(u) for u in total_urls])) # how many restaurants we got"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong> 1.2. Crawl Michelin restaurant pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we download all the HTML from the urls and save them in a folder and divide each of them in separate folder_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler = Crawler()\n",
    "crawler.save_all_as_html('dataset/restaurant_urls.txt') # See actual implementation inside 'crawler.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file count: 1983\n"
     ]
    }
   ],
   "source": [
    "path = 'restaurants_html'\n",
    "count = crawler.count_files(path)\n",
    "print('file count:', count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The save_all_as_html function utilizes multi-threading to achieve optimal performance, generating approximately 20 threads concurrently. Within each loop for a page, each thread is tasked with downloading around a single URL, making it extremely efficient. Consequently, the function successfully downloaded 2,034 out of 2,037 files in under one minute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong> 1.3 Parse downloaded pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of the information we desire for each restaurant and their format is as follows:\n",
    "\n",
    "    Restaurant Name (to save as restaurantName): string;\n",
    "    Address (to save as address): string;\n",
    "    City (to save as city): string;\n",
    "    Postal Code (to save as postalCode): string;\n",
    "    Country (to save as country): string;\n",
    "    Price Range (to save as priceRange): string;\n",
    "    Cuisine Type (to save as cuisineType): string;\n",
    "    Description (to save as description): string;\n",
    "    Facilities and Services (to save as facilitiesServices): list of strings;\n",
    "    Accepted Credit Cards (to save as creditCards): list of strings;\n",
    "    Phone Number (to save as phoneNumber): string;\n",
    "    URL to the Restaurant Page (to save as website): string.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To parse those information we can just inspect one html to see how those information are stored as we did before.<br>\n",
    "Most of the information can be retrieved in the following json script at the end of each HTML file:\n",
    "```js\n",
    "<script type=\"application/ld+json\">{\"@context\":\"http://schema.org\",\"address\":{\"@type\":\"PostalAddress\",\"streetAddress\":\"Piazza Salvo d'Acquisto 16\",\"addressLocality\":\"Lamezia Terme\",\"postalCode\":\"88046\",\"addressCountry\":\"ITA\",\"addressRegion\":\"Calabria\"},\"name\":\"Abbruzzino Oltre\",\"image\":\"https://axwwgrkdco.cloudimg.io/v7/__gmpics3__/f19d37d6b9da437fa06b6f9406645056.jpg?width=1000\",\"@type\":\"Restaurant\",\"review\":{\"@type\":\"Review\",\"datePublished\":\"2024-09-11T07:32\",\"name\":\"Abbruzzino Oltre\",\"description\":\"This restaurant, the new home of young chef Luca Abbruzzino, occupies the first floor of a historic palazzo in the town centre which has recently been converted into a small hotel offering six ...\",\"author\":{\"@type\":\"Person\",\"name\":\"Michelin Inspector\"}},\"telephone\":\"+39 0968 188 8038\",\"knowsLanguage\":\"en-IT\",\"acceptsReservations\":\"No\",\"servesCuisine\":\"Contemporary\",\"url\":\"https://guide.michelin.com/en/calabria/lamezia-terme/restaurant/abbruzzino-oltre\",\"currenciesAccepted\":\"EUR\",\"paymentAccepted\":\"American Express credit card, Credit card / Debit card accepted, Mastercard credit card, Visa credit card\",\"award\":\"Selected: Good cooking\",\"brand\":\"MICHELIN Guide\",\"hasDriveThroughService\":\"False\",\"latitude\":38.9770969,\"longitude\":16.3202202,\"hasMap\":\"https://www.google.com/maps/search/?api=1&query=38.9770969%2C16.3202202\"}</script>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"images/restaurant_page.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a parse_restaurant function that given a html, it parses all the information we need and returns it as a dictionary, we also decided to keep region as an extra column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restaurantName: La Trattoria Enrico Bartolini\n",
      "address: Località Badiola\n",
      "city: Castiglione della Pescaia\n",
      "postalCode: 58043\n",
      "country: ITA\n",
      "region: Tuscany\n",
      "priceRange: €€€€\n",
      "cuisineType: Mediterranean Cuisine, Grills\n",
      "description: After a majestic picture-postcard approach via a long avenue lined with cypress trees and maritime pines, passing vineyards and Maremma cattle along the way, you finally arrive at this restaurant which serves trattoria-style cuisine full of intense, familiar and reassuring flavours. The decor here is elegant with the occasional rustic touch, while the service is of the highest level yet pleasantly friendly and informal. Welcome to Bartolini’s Maremma restaurant! Here, resident chef Bruno De Moura Cossio offers a choice of dishes with one common denominator, namely charcoal grilling. All the dishes served here have been grilled in some way, so that they have a distinctive barbecued flavour. However, although the chef’s Brazilian origins are obvious in many different ways, the ingredients are resolutely local, some even from the restaurant’s own farm. The friendly service makes guests feel completely at home, while the excellent wine selection is an added attraction – those produced on the estate itself are highly recommended.\n",
      "facilitiesServices: ['Air conditioning', 'Car park', 'Garden or park', 'Interesting wine list', 'Terrace']\n",
      "creditCards: ['Amex', 'Mastercard', 'Visa']\n",
      "phoneNumber: +39 0564 944322\n",
      "website: https://www.enricobartolini.net/ristorante-la-trattoria-castiglione\n"
     ]
    }
   ],
   "source": [
    "parser = Parser()\n",
    "info = parser.parse_restaurant('restaurants_html/1/la-trattoria-enrico-bartolini.html') #Test\n",
    "parser.show_restaurant_info(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a tsv file with all the informations of all the restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to dataset/restaurant_info.tsv\n"
     ]
    }
   ],
   "source": [
    "root = 'restaurants_html'\n",
    "output= 'dataset/restaurant_info.tsv'\n",
    "parser.save_all_restaurant_info_to_tsv(root, output) #actual implementation in Parser class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('dataset/restaurant_info.tsv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <strong> Search Engine </strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong> 2.0.0. Preprocessing the Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building the search engine, we need to prepare and clean the restaurant descriptions in our dataset. To accomplish this, we created a class named Preprocessor in preprocessor.py. This class leverages the nltk library to process the text in the description column. It removes stopwords and punctuation, converts the text to lowercase, and applies stemming to reduce words to their base forms. This preprocessing step ensures that the descriptions are standardized, making them more suitable for efficient search and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/pavka/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/pavka/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_table('dataset/restaurant_info.tsv')\n",
    "preprocessor = Preprocessor()\n",
    "df = preprocessor.filter(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's drop the column of description as we don't need it anymore and save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='description',inplace=True)\n",
    "df.to_csv('dataset/restaurant_info_filtered.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong> 2.1. Conjunctive Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(\"dataset/restaurant_info_filtered.tsv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong> 2.1.1. Create Your Index!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a vocabulary that maps each word to a unique integer (term_id) and save it in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_descriptions = df['description_filtered'].str.cat(sep=' ')\n",
    "all_descriptions = list(set(all_descriptions.split(\" \")))\n",
    "vocabulary = {word:id for id, word in enumerate(all_descriptions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this vocabulary to a file with utf-8 encoding in order to be able to handle all the characters\n",
    "with open('dataset/vocabulary.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['word', 'term_id'])  # Header\n",
    "    for word, id in vocabulary.items():\n",
    "        writer.writerow([word, id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create an inverted index and save it into a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = pd.read_csv(\"dataset/vocabulary.csv\")\n",
    "df = pd.read_table(\"dataset/restaurant_info_filtered.tsv\")\n",
    "df = df[['restaurantName','description_filtered']]\n",
    "df['description_filtered'] = df['description_filtered'].str.split(\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word_to_restaurants = defaultdict(list)\n",
    "\n",
    "# Iterate through the restaurant descriptions and update the dictionary\n",
    "for i, row in df.iterrows():\n",
    "    for word in row['description_filtered']:\n",
    "        word_to_restaurants[word].append(row['restaurantName'])\n",
    "\n",
    "# Add the 'restaurants_containing_word' column to the vocabulary DataFrame\n",
    "vocabulary['restaurants_containing_word'] = vocabulary['word'].apply(lambda x: word_to_restaurants[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>term_id</th>\n",
       "      <th>restaurants_containing_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mattiacci</td>\n",
       "      <td>0</td>\n",
       "      <td>[La Gioconda]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>basil</td>\n",
       "      <td>1</td>\n",
       "      <td>[Il Buco, Aria, Regallo, La Caravella dal 1959...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>betray</td>\n",
       "      <td>2</td>\n",
       "      <td>[Albergaccio di Castellina]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alway</td>\n",
       "      <td>3</td>\n",
       "      <td>[Dal Pescatore, Osteria dell'Arco, Marcelin, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mascia</td>\n",
       "      <td>4</td>\n",
       "      <td>[San Domenico]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7780</th>\n",
       "      <td>discreetli</td>\n",
       "      <td>7780</td>\n",
       "      <td>[Morelli, Marelet, GioEle]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7781</th>\n",
       "      <td>peopl</td>\n",
       "      <td>7781</td>\n",
       "      <td>[Hosteria Giusti, Franceschetta 58, Taverna Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7782</th>\n",
       "      <td>sebada</td>\n",
       "      <td>7782</td>\n",
       "      <td>[Sa Domu Sarda]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7783</th>\n",
       "      <td>florian</td>\n",
       "      <td>7783</td>\n",
       "      <td>[Umberto De Martino, Castel fine dining]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>pergola-shad</td>\n",
       "      <td>7784</td>\n",
       "      <td>[Trattoria della Fortuna]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7785 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word  term_id                        restaurants_containing_word\n",
       "0        mattiacci        0                                      [La Gioconda]\n",
       "1            basil        1  [Il Buco, Aria, Regallo, La Caravella dal 1959...\n",
       "2           betray        2                        [Albergaccio di Castellina]\n",
       "3            alway        3  [Dal Pescatore, Osteria dell'Arco, Marcelin, A...\n",
       "4           mascia        4                                     [San Domenico]\n",
       "...            ...      ...                                                ...\n",
       "7780    discreetli     7780                         [Morelli, Marelet, GioEle]\n",
       "7781         peopl     7781  [Hosteria Giusti, Franceschetta 58, Taverna Ro...\n",
       "7782        sebada     7782                                    [Sa Domu Sarda]\n",
       "7783       florian     7783           [Umberto De Martino, Castel fine dining]\n",
       "7784  pergola-shad     7784                          [Trattoria della Fortuna]\n",
       "\n",
       "[7785 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save inverted index into a file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = {term_id:rs for term_id, rs in zip(vocabulary['term_id'], vocabulary['restaurants_containing_word'])}\n",
    "with open('dataset/inverted_index.json', 'w') as jsonfile:\n",
    "    json.dump(inverted_index, jsonfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong> 2.1.2. Execute the Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def searching(query, df, vocabulary, inverted_index):\n",
    "    # Process the query terms\n",
    "    query_text = word_tokenize(query.lower())  # Tokenize and lowercase query\n",
    "    term_ids = []  # List to store term IDs for query text\n",
    "    \n",
    "    # Check each query term in the vocabulary\n",
    "    for term in query_text:\n",
    "        if term in vocabulary:  # Check if term is included in vocabulary\n",
    "            term_ids.append(vocabulary[term])\n",
    "    \n",
    "    # Find restaurants containing all query terms\n",
    "    if not term_ids:\n",
    "        return []  # No terms matched in vocabulary \n",
    "    \n",
    "    # Get the initial list of restaurant IDs that contain the first term\n",
    "    ideal_restaurants = set(inverted_index.get(str(term_ids[0]), []))\n",
    "    \n",
    "    # Narrow down results for each additional term\n",
    "    for term_id in term_ids[1:]:\n",
    "        ideal_restaurants.intersection_update(inverted_index.get(str(term_id), []))\n",
    "        \n",
    "    \n",
    "    # Retrieve restaurant details from the DataFrame\n",
    "    result = []\n",
    "    for restaurant_id in ideal_restaurants:\n",
    "        restaurant = df.loc[df[\"restaurantName\"] == restaurant_id].iloc[0]\n",
    "        result.append({\n",
    "            \"restaurantName\": restaurant[\"restaurantName\"],\n",
    "            \"address\": restaurant[\"address\"],\n",
    "            \"description_filtered\": restaurant[\"description_filtered\"],\n",
    "            \"website\": restaurant[\"website\"]\n",
    "        })\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ideal_restaurants = searching(\"modern seasonal cuisine\", df, vocabulary, inverted_index)\n",
    "ideal_restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test of the function\n",
    "ideal_restaurants = searching(\"modern seasonal cuisine\", df, vocabulary, inverted_index)\n",
    "\n",
    "for restaurant in ideal_restaurants:\n",
    "    print(f\"Restaurant Name: {restaurant['restaurantName']}\")\n",
    "    print(f\"Address: {restaurant['address']}\")\n",
    "    print(f\"Description: {restaurant['description_filtered']}\")\n",
    "    print(f\"Website: {restaurant['website']}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <strong> 2.2. Ranked Search Engine with TF-IDF and Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong> 2.2.1 Inverted Index with TF-IDF Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each restaurant description, calculate the term frequency for each word\n",
    "def tf(df, vocabulary):\n",
    "    tf_dict = defaultdict(lambda: defaultdict(int))  # Nested dictionary to store term counts per document\n",
    "    for idx, row in df.iterrows():\n",
    "        description = row[\"description_filtered\"]\n",
    "        restaurant_id = row[\"restaurantName\"]\n",
    "        \n",
    "        \n",
    "        for term in description:\n",
    "            if term in vocabulary:  \n",
    "                term_id = vocabulary[term]\n",
    "                tf_dict[restaurant_id][term_id] += 1  # Increment count for term_id in this restaurant\n",
    "    \n",
    "    \n",
    "    # Convert raw counts to term frequencies (TF)\n",
    "    for restaurant_id, term_counts in tf_dict.items():\n",
    "        total_terms = sum(term_counts.values())\n",
    "        for term_id in term_counts:\n",
    "            term_counts[term_id] /= total_terms  # Normalize by dividing by total terms\n",
    "    \n",
    "    return tf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate inverse document frequency (IDF) for each term\n",
    "def idf(tf_dict, total_documents):\n",
    "    idf_dict = {}\n",
    "    for term_id in vocabulary.values():\n",
    "        doc_count = sum(1 for doc_terms in tf_dict.values() if term_id in doc_terms)\n",
    "        idf_dict[term_id] = math.log(total_documents / (1 + doc_count))  # Use 1 + doc_count to avoid division by zero\n",
    "    return idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate TF-IDF scores and create an updated inverted index\n",
    "def tf_idf_inverted_index(tf_dict, idf_dict):\n",
    "    tf_idf_index = defaultdict(list)\n",
    "    \n",
    "    for restaurant_id, term_counts in tf_dict.items():\n",
    "        for term_id, tf in term_counts.items():\n",
    "            tf_idf_score = tf * idf_dict[term_id]  # TF-IDF calculation\n",
    "            tf_idf_index[term_id].append((restaurant_id, tf_idf_score))\n",
    "    \n",
    "    return tf_idf_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's combine all the functions above in order to calculate the TF, IDF, and TF-IDF scores, and store the updated inverted index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate TF\n",
    "tf_dict = tf(df, vocabulary)\n",
    "\n",
    "# Step 2: Calculate IDF\n",
    "total_documents = len(df)\n",
    "idf_dict = idf(tf_dict, total_documents)\n",
    "\n",
    "# Step 3: Build the TF-IDF Inverted Index\n",
    "tf_idf_inverted_index = tf_idf_inverted_index(tf_dict, idf_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong> 2.2.2. Execute the Ranked Query"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADMenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
